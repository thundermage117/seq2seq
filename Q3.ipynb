{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Transformed sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>udaxihhe</td>\n",
       "      <td>fmvmfthn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xdvxrcsn</td>\n",
       "      <td>suiaveib</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bacghqta</td>\n",
       "      <td>zgvwmloh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rgwuwrnh</td>\n",
       "      <td>lmhdulik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>osizayzf</td>\n",
       "      <td>wfysmuhe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6995</th>\n",
       "      <td>jnozsubc</td>\n",
       "      <td>mnhmecqd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6996</th>\n",
       "      <td>vpzkyffp</td>\n",
       "      <td>qqpmoheo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6997</th>\n",
       "      <td>syuftisv</td>\n",
       "      <td>ibuldqib</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6998</th>\n",
       "      <td>ynkfgztm</td>\n",
       "      <td>zetqlfbh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6999</th>\n",
       "      <td>pivsstbe</td>\n",
       "      <td>plccmpbd</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sentence Transformed sentence\n",
       "0     udaxihhe             fmvmfthn\n",
       "1     xdvxrcsn             suiaveib\n",
       "2     bacghqta             zgvwmloh\n",
       "3     rgwuwrnh             lmhdulik\n",
       "4     osizayzf             wfysmuhe\n",
       "...        ...                  ...\n",
       "6995  jnozsubc             mnhmecqd\n",
       "6996  vpzkyffp             qqpmoheo\n",
       "6997  syuftisv             ibuldqib\n",
       "6998  ynkfgztm             zetqlfbh\n",
       "6999  pivsstbe             plccmpbd\n",
       "\n",
       "[7000 rows x 2 columns]"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing the training dataset\n",
    "dataset_train = pd.read_csv('train_data.csv')\n",
    "dataset_train\n",
    "\n",
    "#dataset_train = dataset_train[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lang:\n",
    "  def __init__(self, name):\n",
    "    self.name = name\n",
    "    self.word2index = {}\n",
    "    self.word2count = {}\n",
    "    self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "    self.n_words = 2  # Count SOS and EOS\n",
    "  def addSentence(self, sentence):\n",
    "    for word in sentence:\n",
    "      self.addWord(word)\n",
    "  def addWord(self, word):\n",
    "    if word not in self.word2index:\n",
    "      self.word2index[word] = self.n_words\n",
    "      self.word2count[word] = 1\n",
    "      self.index2word[self.n_words] = word\n",
    "      self.n_words += 1\n",
    "    else:\n",
    "      self.word2count[word] += 1\n",
    "  \n",
    "\n",
    "# create an object of the Lang class for each language\n",
    "input_lang = Lang('input')\n",
    "output_lang = Lang('output')\n",
    "\n",
    "# create a list of all the sentences in the training data\n",
    "input_sentences = dataset_train['Sentence'].values.tolist()\n",
    "output_sentences = dataset_train['Transformed sentence'].values.tolist()\n",
    "\n",
    "# add each sentence to the corresponding language\n",
    "for i in range(len(input_sentences)):\n",
    "  input_lang.addSentence(input_sentences[i])\n",
    "  output_lang.addSentence(output_sentences[i])\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'SOS',\n",
       " 1: 'EOS',\n",
       " 2: 'u',\n",
       " 3: 'd',\n",
       " 4: 'a',\n",
       " 5: 'x',\n",
       " 6: 'i',\n",
       " 7: 'h',\n",
       " 8: 'e',\n",
       " 9: 'v',\n",
       " 10: 'r',\n",
       " 11: 'c',\n",
       " 12: 's',\n",
       " 13: 'n',\n",
       " 14: 'b',\n",
       " 15: 'g',\n",
       " 16: 'q',\n",
       " 17: 't',\n",
       " 18: 'w',\n",
       " 19: 'o',\n",
       " 20: 'z',\n",
       " 21: 'y',\n",
       " 22: 'f',\n",
       " 23: 'k',\n",
       " 24: 'm',\n",
       " 25: 'l',\n",
       " 26: 'j',\n",
       " 27: 'p'}"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_lang.index2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size,hidden_size, num_layers=1, dropout_p=0.2):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        \n",
    "        self.lstm = nn.GRU(embedding_size, hidden_size, num_layers,batch_first= True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        embedded = self.embedding(x)\n",
    "        embedded = self.dropout(embedded)\n",
    "        output, hidden = self.lstm(embedded)\n",
    "        return output, hidden\n",
    "\n",
    "    # Predict function to take word as input and output a tensor\n",
    "    def predict(self, word):\n",
    "        with torch.no_grad():\n",
    "            for i in range(len(word)):\n",
    "                x = torch.tensor([[input_lang.word2index[word[i]]]])\n",
    "                x = x.to(device)\n",
    "                output, hidden = self.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder that takes the hidden state of the encoder and outputs a word\n",
    "\n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size,num_layers=1, dropout_p=0.2):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size,num_layers, batch_first=True)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "\n",
    "    def forward(self, encoder_hidden_state, target=None, teacher_forcing_ratio=0.9):\n",
    "        # Initialize decoder hidden state as encoder hidden state\n",
    "        decoder_hidden_state = encoder_hidden_state\n",
    "        # Initialize decoder input as SOS_token\n",
    "        decoder_input = torch.tensor([[0]], device=device)\n",
    "        # Initialize output list\n",
    "        output = []\n",
    "        output_words = []\n",
    "\n",
    "        for i in range(9):\n",
    "            #print(decoder_input.shape,decoder_hidden_state.shape)\n",
    "            decoder_output, decoder_hidden_state = self.forward_step(decoder_input, decoder_hidden_state)\n",
    "            \n",
    "            # Choose top word from decoder's output\n",
    "            top_word = decoder_output.argmax(2)\n",
    "            output_words.append(top_word.item())\n",
    "            # Append the probabiities to the output list\n",
    "            output.append(decoder_output)\n",
    "            # Next input is previous output\n",
    "            decoder_input = top_word\n",
    "            if(target is not None and np.random.random() < teacher_forcing_ratio):\n",
    "                decoder_input = target[:,i].unsqueeze(1)\n",
    "            decoder_hidden_state = decoder_hidden_state.detach()\n",
    "            # Stop decoding when EOS_token is reached\n",
    "            #if top_word.item() == 1:\n",
    "            #    break\n",
    "        # Convert output list to tensor\n",
    "        output = torch.cat(output, dim=1)\n",
    "        return output, output_words\n",
    "        \n",
    "    \n",
    "    def forward_step(self, input, hidden):\n",
    "        #print(input.shape,hidden.shape)\n",
    "        output = self.embedding(input)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.out(output)\n",
    "        #output = self.dropout(output)\n",
    "        return output, hidden\n",
    "    \n",
    "    # Predict function to take hidden state of encoder and output a word\n",
    "    def predict(self, hidden):\n",
    "        with torch.no_grad():\n",
    "            input = torch.tensor([[0]], device=device)\n",
    "            output, hidden = self.forward_step(input, hidden)\n",
    "            return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass data thru encoder\n",
    "def encoder_pass(input_tensor, encoder):\n",
    "  encoder_hidden = encoder(input_tensor)[1]\n",
    "  return encoder_hidden\n",
    "\n",
    "# pass data thru decoder\n",
    "def decoder_pass(decoder_input, decoder_hidden, decoder):\n",
    "  decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "  return decoder_output, decoder_hidden\n",
    "\n",
    "# pass data thru encoder and decoder\n",
    "def encoder_decoder_pass(input_tensor, decoder_input, encoder, decoder):\n",
    "  encoder_hidden = encoder_pass(input_tensor, encoder)\n",
    "  decoder_output, decoder_hidden = decoder_pass(decoder_input, encoder_hidden, decoder)\n",
    "  return decoder_output, decoder_hidden\n",
    "\n",
    "# convert a sentence to a tensor\\\n",
    "def sentence_to_tensor(lang, sentence):\n",
    "  indexes = [lang.word2index[word] for word in sentence]\n",
    "  EOS_token = 1\n",
    "  indexes.append(EOS_token)\n",
    "  return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "# convert a tensor to a sentence\n",
    "def tensor_to_sentence(lang, tensor):\n",
    "  sentence = []\n",
    "  for i in tensor:\n",
    "    word = lang.index2word[i.item()]\n",
    "    sentence.append(word)\n",
    "  return sentence\n",
    "\n",
    "# convert a list of sentences to a list of tensors\n",
    "def sentences_to_tensors(lang, sentences):\n",
    "  tensors = []\n",
    "  for sentence in sentences:\n",
    "    tensors.append(sentence_to_tensor(lang, sentence))\n",
    "  return tensors\n",
    "\n",
    "# convert a list of tensors to a list of sentences\n",
    "def tensors_to_sentences(lang, tensors):\n",
    "  sentences = []\n",
    "  for tensor in tensors:\n",
    "    sentences.append(tensor_to_sentence(lang, tensor))\n",
    "  return sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create tensors for the input and output sentences\n",
    "input_tensors = sentences_to_tensors(input_lang, input_sentences)\n",
    "output_tensors = sentences_to_tensors(output_lang, output_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 9])\n",
      "torch.Size([1, 9, 256]) torch.Size([2, 1, 256])\n",
      "decoder\n",
      "torch.Size([1, 9, 28])\n",
      "[13, 13, 13, 13, 25, 25, 25, 17, 17]\n",
      "tensor([[2, 3, 4, 5, 6, 7, 7, 8, 1]], device='cuda:0')\n",
      "torch.Size([1, 9])\n"
     ]
    }
   ],
   "source": [
    "encoder = EncoderRNN(input_lang.n_words, 256, 256, 2).to(device)\n",
    "decoder = DecoderRNN(256, output_lang.n_words,2).to(device)\n",
    "\n",
    "test_X = input_tensors[0].view(1,-1)\n",
    "test_Y = output_tensors[0]\n",
    "\n",
    "print(test_X.shape)\n",
    "encoder_output, encoder_hidden = encoder(test_X)\n",
    "print(encoder_output.shape, encoder_hidden.shape)\n",
    "\n",
    "#encoder_hidden = encoder_hidden.view(1,1,-1)\n",
    "print(\"decoder\")\n",
    "decoder_output, decoder_word = decoder(encoder_hidden)\n",
    "# convert list to tensor\n",
    "#decoder_output = torch.tensor(decoder_output, dtype=torch.long, device=device).view(-1, 1)\n",
    "#print(decoder_output)\n",
    "print(decoder_output.shape)\n",
    "print(decoder_word)\n",
    "print(test_X)\n",
    "print(test_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderDecoder(nn.Module):\n",
    "  def __init__(self, input_lang, output_lang,hidden_size, num_layers=1, dropout_p=0.1):\n",
    "    super(EncoderDecoder, self).__init__()\n",
    "    self.encoder = EncoderRNN(input_lang.n_words, hidden_size, hidden_size, num_layers).to(device)\n",
    "    self.decoder = DecoderRNN(hidden_size, output_lang.n_words,num_layers).to(device)\n",
    "\n",
    "  def forward(self, input_tensor, output_tensor=None):\n",
    "    encoder_hidden = self.encoder(input_tensor)[1]\n",
    "    decoder_output,decoder_word = self.decoder(encoder_hidden, output_tensor)\n",
    "    #print(decoder_output.shape, input_tensor.shape)\n",
    "    return decoder_output, decoder_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(input_tensors, output_tensors, model, criterion, optimizer, n_epochs=1000):\n",
    "  losses = []\n",
    "  for epoch in range(n_epochs):\n",
    "    epoch_loss = 0\n",
    "    for i in range(len(input_tensors)):\n",
    "      input_tensor = input_tensors[i].view(1,-1)\n",
    "      output_tensor = output_tensors[i].view(1,-1)\n",
    "      optimizer.zero_grad()\n",
    "      output,_ = model(input_tensor, output_tensor)\n",
    "      loss = criterion(output.view(9,-1), output_tensor.view(9))\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      epoch_loss += loss.item()\n",
    "      if(i%1000==0):\n",
    "        print(\"Epoch: {}, Iteration: {}, Loss: {:.5f}\".format(epoch, i, loss.item()))\n",
    "    losses.append(epoch_loss)\n",
    "    print('Epoch: {}, Loss: {:.5f}'.format(epoch, epoch_loss))\n",
    "  return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9, 1])\n",
      "torch.Size([7000, 9, 1])\n"
     ]
    }
   ],
   "source": [
    "print(input_tensors[0].shape)\n",
    "input_tensors = torch.cat(input_tensors, dim=0)\n",
    "output_tensors = torch.cat(output_tensors, dim=0)\n",
    "input_tensors= input_tensors.view(-1,9,1)\n",
    "output_tensors = output_tensors.view(-1,9,1)\n",
    "print(input_tensors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_from_to(input_tensors, output_tensors, seq2seq, criterion, optimizer, n_epochs, start_id, end_id):\n",
    "  return train(input_tensors[start_id:end_id], output_tensors[start_id:end_id], seq2seq, criterion, optimizer, n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.0001\n",
    "n_epochs = 25\n",
    "hidden_size = 512\n",
    "num_layers = 2\n",
    "\n",
    "seq2seq = EncoderDecoder(input_lang, output_lang,hidden_size,num_layers).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(seq2seq.parameters(), lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Iteration: 0, Loss: 0.01552\n",
      "Epoch: 0, Iteration: 1000, Loss: 0.04176\n",
      "Epoch: 0, Iteration: 2000, Loss: 0.15018\n",
      "Epoch: 0, Iteration: 3000, Loss: 0.04640\n",
      "Epoch: 0, Iteration: 4000, Loss: 0.17135\n",
      "Epoch: 0, Iteration: 5000, Loss: 0.08056\n",
      "Epoch: 0, Iteration: 6000, Loss: 0.17101\n",
      "Epoch: 0, Loss: 910.35358\n"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "n_epochs = 1\n",
    "lr=0.00001\n",
    "start = 0\n",
    "end = 7000\n",
    "\n",
    "optimizer = torch.optim.AdamW(seq2seq.parameters(), lr, weight_decay=0.0000001, amsgrad=True)\n",
    "losses = train_from_to(input_tensors, output_tensors, seq2seq, criterion, optimizer, n_epochs, start, end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model\n",
    "#torch.save(seq2seq.state_dict(), 'seq2seq_1_5k.pth')\n",
    "\n",
    "# load the model\n",
    "seq2seq = EncoderDecoder(input_lang, output_lang,hidden_size,num_layers).to(device)\n",
    "seq2seq.load_state_dict(torch.load('seq2seq.pth'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sentence: ['x', 'r', 'b', 'l', 'h', 'u', 'c', 'y', 'EOS']\n",
      "Predicted sentence: ['u', 'g', 'q', 'q', 'l', 'q', 'v', 'w', 'EOS']\n",
      "Actual sentence: ['u', 'g', 'q', 'q', 'l', 'q', 'v', 'w', 'EOS']\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "\n",
    "#xrblhucy,ugqqlqvw\n",
    "\n",
    "\n",
    "\n",
    "test_X = sentence_to_tensor(input_lang, 'xrblhucy')\n",
    "test_Y = sentence_to_tensor(output_lang, 'ugqqlqvw')\n",
    "\n",
    "_, output_words = seq2seq(test_X.view(1,-1), test_Y.view(1,-1))\n",
    "output_words = tensor_to_sentence(output_lang, torch.tensor(output_words, dtype=torch.long, device=device))\n",
    "test_X = tensor_to_sentence(input_lang, test_X)\n",
    "test_Y = tensor_to_sentence(output_lang, test_Y)\n",
    "\n",
    "print('Input sentence: {}'.format(test_X))\n",
    "print('Predicted sentence: {}'.format(output_words))\n",
    "print('Actual sentence: {}'.format(test_Y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fn to print output for a given input given the encoder and decoder\n",
    "def evaluate_enc(encoder, decoder, sentence):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = sentence_to_tensor(input_lang, sentence)\n",
    "        input_tensor = input_tensor.view(1,-1)\n",
    "        encoder_hidden = encoder(input_tensor)[1]\n",
    "        decoder_output, decoder_word = decoder(encoder_hidden)\n",
    "        word = tensor_to_sentence(output_lang, torch.tensor(decoder_word, dtype=torch.long, device=device))\n",
    "        # remove EOS token\n",
    "        word = word[:-1]\n",
    "        return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['u', 'g', 'q', 'q', 'l', 'q', 'v', 'w']"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_enc(seq2seq.encoder, seq2seq.decoder, 'xrblhucy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check number of correct predictions\n",
    "def check_accuracy(input_tensors, output_tensors, seq2seq):\n",
    "  correct = 0\n",
    "  for i in range(len(input_tensors)):\n",
    "    input_tensor = input_tensors[i].view(1,-1)\n",
    "    output_tensor = output_tensors[i].view(1,-1)\n",
    "    with torch.no_grad():\n",
    "      _, output_words = seq2seq(input_tensor)\n",
    "\n",
    "      output_words = tensor_to_sentence(output_lang, torch.tensor(output_words, dtype=torch.long, device=device))\n",
    "      output_words = ''.join(output_words)\n",
    "      output_tensor = output_tensor.view(-1)\n",
    "      output_tensor = tensor_to_sentence(output_lang, output_tensor)\n",
    "      output_tensor = ''.join(output_tensor)\n",
    "      if(output_words == output_tensor):\n",
    "        correct += 1\n",
    "\n",
    "  return correct\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "857"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check accuracy on the training data\n",
    "correct = check_accuracy(input_tensors[:1000], output_tensors[:1000], seq2seq)\n",
    "correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check how many characters match in the two strings\n",
    "def check(pred: str, true: str):\n",
    "    correct = 0\n",
    "    for a, b in zip(pred, true):\n",
    "        if a == b:\n",
    "            correct += 1\n",
    "\n",
    "    # Prediction is more than 8 letters, so penalize for every extra letter.\n",
    "    correct -= max(0, len(pred) - len(true))\n",
    "    correct = max(0, correct)\n",
    "    return correct\n",
    "\n",
    "# Function to score the model's performance\n",
    "def evaluate(encoder, decoder):\n",
    "\n",
    "    # Train data\n",
    "    print(\"Obtaining results for training data:\")\n",
    "    train_data = pd.read_csv(\"train_data.csv\").to_numpy()\n",
    "    results = {\n",
    "        \"pred\": [],\n",
    "        \"true\": [],\n",
    "        \"score\": [],\n",
    "    }\n",
    "    correct = [0 for _ in range(9)]\n",
    "    for x, y in train_data:\n",
    "        pred = evaluate_enc(encoder, decoder, x)\n",
    "        #print(pred, y) \n",
    "        score = check(pred, y)\n",
    "        results[\"pred\"].append(pred)\n",
    "        results[\"true\"].append(y)\n",
    "        results[\"score\"].append(score)\n",
    "\n",
    "        correct[score] += 1\n",
    "    print(\"Train dataset results:\")\n",
    "    for num_chr in range(9):\n",
    "        print(\n",
    "            f\"Number of predictions with {num_chr} correct predictions: {correct[num_chr]}\"\n",
    "        )\n",
    "    points = sum(correct[4:6]) * 0.5 + sum(correct[6:])\n",
    "    print(f\"Points: {points}\")\n",
    "    # Save predicitons and true sentences to inspect manually if required.\n",
    "    pd.DataFrame.from_dict(results).to_csv(\"results_train.csv\", index=False)\n",
    "\n",
    "    #----------------------------------------------------------------------------------\n",
    "\n",
    "    print(\"Obtaining metrics for eval data:\")\n",
    "    eval_data = pd.read_csv(\"eval_data.csv\").to_numpy()\n",
    "    results = {\n",
    "        \"pred\": [],\n",
    "        \"true\": [],\n",
    "        \"score\": [],\n",
    "    }\n",
    "    correct = [0 for _ in range(9)]\n",
    "    for x, y in eval_data:\n",
    "        pred = evaluate_enc(encoder, decoder, x)\n",
    "        score = check(pred, y)\n",
    "        results[\"pred\"].append(pred)\n",
    "        results[\"true\"].append(y)\n",
    "        results[\"score\"].append(score)\n",
    "\n",
    "        correct[score] += 1\n",
    "    print(\"Eval dataset results:\")\n",
    "    for num_chr in range(9):\n",
    "        print(\n",
    "            f\"Number of predictions with {num_chr} correct predictions: {correct[num_chr]}\"\n",
    "        )\n",
    "    points = sum(correct[4:6]) * 0.5 + sum(correct[6:])\n",
    "    marks = round(min(2, points / 1400 * 2) * 2) / 2  # Rounds to the nearest 0.5\n",
    "    print(f\"Points: {points}\")\n",
    "    print(f\"Marks: {marks}\")\n",
    "    # Save predicitons and true sentences to inspect manually if required.\n",
    "    pd.DataFrame.from_dict(results).to_csv(\"results_eval.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining results for training data:\n",
      "Train dataset results:\n",
      "Number of predictions with 0 correct predictions: 0\n",
      "Number of predictions with 1 correct predictions: 591\n",
      "Number of predictions with 2 correct predictions: 227\n",
      "Number of predictions with 3 correct predictions: 52\n",
      "Number of predictions with 4 correct predictions: 9\n",
      "Number of predictions with 5 correct predictions: 5\n",
      "Number of predictions with 6 correct predictions: 4\n",
      "Number of predictions with 7 correct predictions: 7\n",
      "Number of predictions with 8 correct predictions: 6105\n",
      "Points: 6123.0\n",
      "Obtaining metrics for eval data:\n",
      "Eval dataset results:\n",
      "Number of predictions with 0 correct predictions: 0\n",
      "Number of predictions with 1 correct predictions: 1476\n",
      "Number of predictions with 2 correct predictions: 445\n",
      "Number of predictions with 3 correct predictions: 72\n",
      "Number of predictions with 4 correct predictions: 7\n",
      "Number of predictions with 5 correct predictions: 0\n",
      "Number of predictions with 6 correct predictions: 0\n",
      "Number of predictions with 7 correct predictions: 0\n",
      "Number of predictions with 8 correct predictions: 0\n",
      "Points: 3.5\n",
      "Marks: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Use function check\n",
    "evaluate(seq2seq.encoder, seq2seq.decoder)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
